{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cat vs Non-cat.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4mayS4XTkoQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "from PIL import Image\n",
        "from scipy import ndimage\n",
        "from dnn_app_utils_v3 import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cYBaSRTUP4J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-3wjrnPi3bg",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "Load data\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTrnJxUnW8mu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data():\n",
        "  train_dataset = h5py.File('datasets/train_catvnoncat.h5', \"r\")\n",
        "  train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # train set features\n",
        "  train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # train set labels\n",
        "\n",
        "  test_dataset = h5py.File('datasets/test_catvnoncat.h5', \"r\")\n",
        "  test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # test set features\n",
        "  test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # test set labels\n",
        "\n",
        "  classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
        "  \n",
        "  train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
        "  test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
        "  \n",
        "  return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyEY8WSuUSXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x_orig, train_y, test_x_orig, test_y, classes = load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VQl6n2mi8OR",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Flatten the dimensions\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dxb6IMbEUU4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x_flatten = train_x_orig.reshape(train_x_orig.shape[0], -1).T   # The \"-1\" makes reshape flatten the remaining dimensions\n",
        "test_x_flatten = test_x_orig.reshape(test_x_orig.shape[0], -1).T\n",
        "\n",
        "# Standardize data to have feature values between 0 and 1.\n",
        "train_x = train_x_flatten/255.\n",
        "test_x = test_x_flatten/255."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRVvM8CTVbX5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layers_dims = [12288, 20, 7, 5, 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTCz0l48WLji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Activation functions----------------\n",
        "def sigmoid(Z):\n",
        "  A = 1/(1+np.exp(-Z))\n",
        "  cache = Z\n",
        "  \n",
        "  return A, cache\n",
        "\n",
        "def relu(Z):\n",
        "  A = np.maximum(0,Z)\n",
        "  \n",
        "  assert(A.shape == Z.shape)\n",
        "  \n",
        "  cache = Z \n",
        "  return A, cache"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AZsWTSnWlGX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Activation Backward---------\n",
        "def relu_backward(dA, cache):\n",
        "  Z = cache\n",
        "  dZ = np.array(dA, copy=True) # just converting dz to a correct object.\n",
        "  \n",
        "  # When z <= 0, set dz to 0 as well. \n",
        "  dZ[Z <= 0] = 0\n",
        "  \n",
        "  assert (dZ.shape == Z.shape)\n",
        "  return dZ\n",
        "\n",
        "def sigmoid_backward(dA, cache):\n",
        "  Z = cache\n",
        "  \n",
        "  s = 1/(1+np.exp(-Z))\n",
        "  dZ = dA * s * (1-s)\n",
        "  \n",
        "  assert (dZ.shape == Z.shape)\n",
        "  return dZ"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNJz-9maXJIF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize parameters of newral network\n",
        "def initialize_parameters_deep(layer_dims):\n",
        "  np.random.seed(1)\n",
        "  parameters = {}\n",
        "  L = len(layer_dims)            # number of layers in the network\n",
        "\n",
        "  for l in range(1, L):\n",
        "      parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]) / np.sqrt(layer_dims[l-1]) #*0.01\n",
        "      parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
        "      \n",
        "      assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l-1]))\n",
        "      assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
        "\n",
        "      \n",
        "  return parameters  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eokhk8LXn9_",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Forward propagation**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVWqdq0rXg2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def linear_forward(A, W, b):\n",
        "  Z = W.dot(A) + b\n",
        "  \n",
        "  assert(Z.shape == (W.shape[0], A.shape[1]))\n",
        "  cache = (A, W, b)\n",
        "  \n",
        "  return Z, cache"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmA3nEnAX6MC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def linear_activation_forward(A_prev, W, b, activation):\n",
        "  \n",
        "  if activation == \"sigmoid\":\n",
        "      # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
        "      Z, linear_cache = linear_forward(A_prev, W, b)\n",
        "      A, activation_cache = sigmoid(Z)\n",
        "  \n",
        "  elif activation == \"relu\":\n",
        "      # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
        "      Z, linear_cache = linear_forward(A_prev, W, b)\n",
        "      A, activation_cache = relu(Z)\n",
        "  \n",
        "  assert (A.shape == (W.shape[0], A_prev.shape[1]))\n",
        "  cache = (linear_cache, activation_cache)\n",
        "\n",
        "  return A, cache"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBveYHodYCzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def L_model_forward(X, parameters):\n",
        "  caches = []\n",
        "  A = X\n",
        "  L = len(parameters) // 2                  # number of layers in the neural network\n",
        "  \n",
        "  # Implement [LINEAR -> RELU]*(L-1). Add \"cache\" to the \"caches\" list.\n",
        "  for l in range(1, L):\n",
        "      A_prev = A \n",
        "      A, cache = linear_activation_forward(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], activation = \"relu\")\n",
        "      caches.append(cache)\n",
        "  \n",
        "  # Implement LINEAR -> SIGMOID. Add \"cache\" to the \"caches\" list.\n",
        "  AL, cache = linear_activation_forward(A, parameters['W' + str(L)], parameters['b' + str(L)], activation = \"sigmoid\")\n",
        "  caches.append(cache)\n",
        "  \n",
        "  assert(AL.shape == (1,X.shape[1]))\n",
        "          \n",
        "  return AL, caches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEF8_C_LYMCW",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "***Compute Cost***\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOuTJrfPYVbn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_cost(AL, Y):\n",
        "  m = Y.shape[1]\n",
        "\n",
        "  # Compute loss from aL and y.\n",
        "  cost = (1./m) * (-np.dot(Y,np.log(AL).T) - np.dot(1-Y, np.log(1-AL).T))\n",
        "  \n",
        "  cost = np.squeeze(cost)      # To make sure your cost's shape is what we expect (this turns [[17]] into 17).\n",
        "  assert(cost.shape == ())\n",
        "  \n",
        "  return cost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pq7bWRbHYe4W",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "***Backward Propagation***\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XB6X0UwbYmnW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def linear_backward(dZ, cache):\n",
        "  A_prev, W, b = cache\n",
        "  m = A_prev.shape[1]\n",
        "\n",
        "  dW = 1./m * np.dot(dZ,A_prev.T)\n",
        "  db = 1./m * np.sum(dZ, axis = 1, keepdims = True)\n",
        "  dA_prev = np.dot(W.T,dZ)\n",
        "  \n",
        "  assert (dA_prev.shape == A_prev.shape)\n",
        "  assert (dW.shape == W.shape)\n",
        "  assert (db.shape == b.shape)\n",
        "  \n",
        "  return dA_prev, dW, db"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bco23twAYxQL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def linear_activation_backward(dA, cache, activation):\n",
        "  linear_cache, activation_cache = cache\n",
        "  \n",
        "  if activation == \"relu\":\n",
        "      dZ = relu_backward(dA, activation_cache)\n",
        "      dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
        "      \n",
        "  elif activation == \"sigmoid\":\n",
        "      dZ = sigmoid_backward(dA, activation_cache)\n",
        "      dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
        "  \n",
        "  return dA_prev, dW, db"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dH-gdZkoY7Qw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Back propagation\n",
        "def L_model_backward(AL, Y, caches):\n",
        "    grads = {}\n",
        "    L = len(caches) # the number of layers\n",
        "    m = AL.shape[1]\n",
        "    Y = Y.reshape(AL.shape) # after this line, Y is the same shape as AL\n",
        "    \n",
        "    # Initializing the backpropagation\n",
        "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
        "    \n",
        "    # Lth layer (SIGMOID -> LINEAR) gradients. Inputs: \"AL, Y, caches\". Outputs: \"grads[\"dAL\"], grads[\"dWL\"], grads[\"dbL\"]\n",
        "    current_cache = caches[L-1]\n",
        "    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, activation = \"sigmoid\")\n",
        "    \n",
        "    for l in reversed(range(L-1)):\n",
        "        # lth layer: (RELU -> LINEAR) gradients.\n",
        "        current_cache = caches[l]\n",
        "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l + 1)], current_cache, activation = \"relu\")\n",
        "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
        "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
        "        grads[\"db\" + str(l + 1)] = db_temp\n",
        "\n",
        "    return grads"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzzUVagOZIA3",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Update Parameters**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdLE4N-0ZNsk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_parameters(parameters, grads, learning_rate):\n",
        "  L = len(parameters) // 2 # number of layers in the neural network\n",
        "\n",
        "  for l in range(L):\n",
        "      parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * grads[\"dW\" + str(l+1)]\n",
        "      parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * grads[\"db\" + str(l+1)]\n",
        "      \n",
        "  return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zwx3vDMnZeC6",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "Prediction \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPBBiaUBZjA-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(X, y, parameters):\n",
        "  m = X.shape[1]\n",
        "  n = len(parameters) // 2 # number of layers in the neural network\n",
        "  p = np.zeros((1,m))\n",
        "  \n",
        "  # Forward propagation\n",
        "  probas, caches = L_model_forward(X, parameters)\n",
        "\n",
        "  \n",
        "  # convert probas to 0/1 predictions\n",
        "  for i in range(0, probas.shape[1]):\n",
        "      if probas[0,i] > 0.5:\n",
        "          p[0,i] = 1\n",
        "      else:\n",
        "          p[0,i] = 0\n",
        "  \n",
        "  #print results\n",
        "  #print (\"predictions: \" + str(p))\n",
        "  #print (\"true labels: \" + str(y))\n",
        "  print(\"Accuracy: \"  + str(np.sum((p == y)/m)))\n",
        "      \n",
        "  return p"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOdtF78mZz4h",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "Print mislabeled images\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IRtaV0XU2N8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def L_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):#lr was 0.009\n",
        "\n",
        "    np.random.seed(1)\n",
        "    costs = []                         # keep track of cost\n",
        "    \n",
        "    # Parameters initialization. \n",
        "    parameters = initialize_parameters_deep(layers_dims)\n",
        "    \n",
        "    # Loop (gradient descent)\n",
        "    for i in range(0, num_iterations):\n",
        "\n",
        "        # Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n",
        "        AL, caches = L_model_forward(X, parameters)\n",
        "        \n",
        "        # Compute cost.\n",
        "        cost = compute_cost(AL, Y)\n",
        "    \n",
        "        # Backward propagation.\n",
        "        grads = L_model_backward(AL, Y, caches)\n",
        " \n",
        "        # Update parameters.\n",
        "        parameters = update_parameters(parameters, grads, learning_rate)\n",
        "                \n",
        "        # Print the cost every 100 training example\n",
        "        if print_cost and i % 100 == 0:\n",
        "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
        "        if print_cost and i % 100 == 0:\n",
        "            costs.append(cost)\n",
        "            \n",
        "    # plot the cost\n",
        "    plt.plot(np.squeeze(costs))\n",
        "    plt.ylabel('cost')\n",
        "    plt.xlabel('iterations (per hundreds)')\n",
        "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
        "    plt.show()\n",
        "    \n",
        "    return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pHbgxvzVWgS",
        "colab_type": "code",
        "outputId": "9be5d307-ec06-4656-ad63-ec1a15e9d964",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        }
      },
      "source": [
        "parameters = L_layer_model(train_x, train_y, layers_dims, num_iterations = 2500, print_cost = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cost after iteration 0: 0.771749\n",
            "Cost after iteration 100: 0.672053\n",
            "Cost after iteration 200: 0.648263\n",
            "Cost after iteration 300: 0.611507\n",
            "Cost after iteration 400: 0.567047\n",
            "Cost after iteration 500: 0.540138\n",
            "Cost after iteration 600: 0.527930\n",
            "Cost after iteration 700: 0.465477\n",
            "Cost after iteration 800: 0.369126\n",
            "Cost after iteration 900: 0.391747\n",
            "Cost after iteration 1000: 0.315187\n",
            "Cost after iteration 1100: 0.272700\n",
            "Cost after iteration 1200: 0.237419\n",
            "Cost after iteration 1300: 0.199601\n",
            "Cost after iteration 1400: 0.189263\n",
            "Cost after iteration 1500: 0.161189\n",
            "Cost after iteration 1600: 0.148214\n",
            "Cost after iteration 1700: 0.137775\n",
            "Cost after iteration 1800: 0.129740\n",
            "Cost after iteration 1900: 0.121225\n",
            "Cost after iteration 2000: 0.113821\n",
            "Cost after iteration 2100: 0.107839\n",
            "Cost after iteration 2200: 0.102855\n",
            "Cost after iteration 2300: 0.100897\n",
            "Cost after iteration 2400: 0.092878\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRKSYQkFERIopFEREpJhCQUREiv0/iNbWsjCeECMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YA7nd7cEVZEb",
        "colab_type": "code",
        "outputId": "20a227f5-7616-4938-e298-e2b53e9ef4f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred_train = predict(train_x, train_y, parameters)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9856459330143539\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU1SdCoIV_en",
        "colab_type": "code",
        "outputId": "94a4f04f-3e32-46ba-d40d-5810c8820643",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred_test = predict(test_x, test_y, parameters)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Il8u89n5WChZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6ZYb7F5zUeY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}